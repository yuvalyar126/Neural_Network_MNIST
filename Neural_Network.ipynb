{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'overflow')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "GENERAL FUNCTIONS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce8cbde247ba6efe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define default parameters\n",
    "default_config = {\n",
    "    'layers': [784, 256, 64, 10],\n",
    "    'learning_rate': 0.1,\n",
    "    'batch_size': 32,\n",
    "    'iterations': 30\n",
    "}\n",
    "\n",
    "top3_models = []  # a list to store the top 3 models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b11f482b66bd6f49"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_model(X_train, y_train, X_val, y_val, X_test, y_test, model_config):\n",
    "    \"\"\"\n",
    "    Run a neural network model with specific configuration.\n",
    "    :param X_train: Training dataset features\n",
    "    :param y_train: Training dataset labels\n",
    "    :param X_val: Validation dataset features\n",
    "    :param y_val: Validation dataset labels\n",
    "    :param X_test: Test dataset features\n",
    "    :param y_test: Test dataset labels\n",
    "    :param model_config: Model configuration parameters\n",
    "    :return: Dictionary with model configuration and scores\n",
    "    \"\"\"\n",
    "    layers = model_config.get('layers', default_config['layers'])\n",
    "    learning_rate = model_config.get('learning_rate', default_config['learning_rate'])\n",
    "    batch_size = model_config.get('batch_size', default_config['batch_size'])\n",
    "    iterations = model_config.get('iterations', default_config['iterations'])\n",
    "    print(f\"Model configuration: layers = {layers}, learning_rate = {learning_rate}, batch_size = {batch_size}, iterations = {iterations}\")\n",
    "    \n",
    "    nn = NeuralNetwork(layers=layers, batch_size=batch_size, learning_rate=learning_rate, iterations=iterations)\n",
    "    nn.fit(X_train, y_train)\n",
    "\n",
    "    train_score = nn.score(X_train, y_train)\n",
    "    val_score = nn.score(X_val, y_val)\n",
    "    test_score = nn.score(X_test, y_test)\n",
    "    # Plot confusion matrix for the test set\n",
    "    nn.plot_confusion_matrix(X_test, y_test)\n",
    "\n",
    "    return {\n",
    "        'layers': layers,\n",
    "        'learning_rate': learning_rate,\n",
    "        'batch_size': batch_size,\n",
    "        'iterations': iterations,\n",
    "        'train_score': train_score,\n",
    "        'val_score': val_score,\n",
    "        'test_score': test_score\n",
    "    }\n",
    "\n",
    "def test_configuration_set(X_train, y_train, X_val, y_val, X_test, y_test, config_set, param_name):\n",
    "    \"\"\"\n",
    "    Test different configurations for a specific isolated parameter\n",
    "    :param X_train: Training dataset features\n",
    "    :param y_train: Training dataset labels\n",
    "    :param X_val: Validation dataset features\n",
    "    :param y_val: Validation dataset labels\n",
    "    :param X_test: Test dataset features\n",
    "    :param y_test: Test dataset labels\n",
    "    :param config_set: Set of configurations to test\n",
    "    :param param_name: Name of the parameter being tested\n",
    "    :return: List of results for each configuration\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    global top3_models  # declare as global \n",
    "    for config in config_set:\n",
    "        model_config = default_config.copy()\n",
    "        model_config.update(config)  \n",
    "        print(f\"The isolated parameter is: {param_name}\")\n",
    "        result = run_model(X_train, y_train, X_val, y_val, X_test, y_test, model_config)\n",
    "        results.append(result)\n",
    "        print(f\"Validation Score: {result['val_score']}\")\n",
    "        print(f\"Test Score: {result['test_score']}\")\n",
    "        print(f\"\\n\\n\\n                               ~~~~~~~~~~~~~~~~~~~~~~~~ NEXT MODEL ~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
    "        \n",
    "      \n",
    "        if len(top3_models) < 3:\n",
    "            top3_models.append(result)\n",
    "        else:\n",
    "            # find the minimum score in the top 3 models to remove\n",
    "            min_score_model = min(top3_models, key=lambda x: x['val_score'])\n",
    "            if result['val_score'] > min_score_model['val_score']:\n",
    "                top3_models.remove(min_score_model)\n",
    "                top3_models.append(result)\n",
    "        \n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50b682455fc904fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "PLOT FUNCTIONS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a32ee86cf989268"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the test scores for different configurations\n",
    "def plot_test_scores(results, param_name):\n",
    "    param_values = []\n",
    "    test_scores = []\n",
    "\n",
    "    for result in results:\n",
    "        param_values.append(result[param_name])\n",
    "        test_scores.append(result['test_score'])\n",
    "\n",
    "    # Sort results by test score in descending order\n",
    "    sorted_indices = sorted(range(len(test_scores)), key=lambda i: test_scores[i], reverse=False)\n",
    "    param_values = [param_values[i] for i in sorted_indices]\n",
    "    test_scores = [test_scores[i] for i in sorted_indices]\n",
    "\n",
    "    y = range(len(param_values))\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bar_height = 0.4\n",
    "\n",
    "    bars = plt.barh(y, test_scores, color='green', height=bar_height, label='Test Score', align='center')\n",
    "\n",
    "    plt.ylabel(param_name)\n",
    "    plt.xlabel('Test Accuracy')\n",
    "    plt.xlim(0.85, 1.0)\n",
    "    other_params = \", \".join([f\"{k.capitalize().replace('_', ' ')}: {v}\" for k, v in default_config.items() if k != param_name])\n",
    "    plt.title(f'Test Accuracy vs {param_name}')\n",
    "    plt.suptitle(other_params, fontsize=10)\n",
    "    plt.yticks(y, param_values)\n",
    "    plt.legend()\n",
    "\n",
    "    for bar in bars:\n",
    "        xval = bar.get_width()\n",
    "        plt.text(xval + 0.01, bar.get_y() + bar.get_height()/2, round(xval, 4), ha='left', va='center')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# create string of other parameters for the plot title\n",
    "def create_other_params_string(config, param_name):\n",
    "    other_params = {k: v for k, v in config.items() if k != param_name}\n",
    "    return \", \".join([f\"{k.capitalize().replace('_', ' ')}: {v}\" for k, v in other_params.items()])    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e83361281f35ab71"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, batch_size, learning_rate, iterations):\n",
    "        \"\"\"\n",
    "        Initialize the neural network with given parameters\n",
    "        :param layers: List of layer sizes for each layer\n",
    "        :param batch_size: Size of each training batch\n",
    "        :param learning_rate: Learning rate for gradient descent\n",
    "        :param iterations: Number of iterations for training\n",
    "        \"\"\"\n",
    "        self.layers = layers\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.weights = self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        Initialize the weights and biases of the network\n",
    "        :return: Dictionary of weights and biases\n",
    "        \"\"\"\n",
    "        weights = {}\n",
    "        for i in range(1, len(self.layers)):\n",
    "            weights[f'W{i}'] = np.random.randn(self.layers[i], self.layers[i - 1]) * np.sqrt(2. / self.layers[i - 1])\n",
    "            weights[f'b{i}'] = np.zeros((self.layers[i], 1))\n",
    "        return weights\n",
    "\n",
    "   \n",
    "    # ReLU activation function\n",
    "    def ReLU(self, Z):\n",
    "        return np.maximum(Z, 0)\n",
    "\n",
    "    # softmax activation function\n",
    "    def softmax(self, Z):\n",
    "        A = np.exp(Z) / np.sum(np.exp(Z), axis=0)\n",
    "        return A\n",
    "\n",
    "\n",
    "    def forward_prop(self, X):\n",
    "        \"\"\"\n",
    "        Perform forward propagation through the network\n",
    "        :param X: Input data\n",
    "        :return: a dictionary with previous results\n",
    "        \"\"\"\n",
    "        memory = {'A0': X}\n",
    "        A = X\n",
    "        for i in range(1, len(self.layers) - 1):\n",
    "            Z = self.weights[f'W{i}'] @ A + self.weights[f'b{i}']\n",
    "            A = self.ReLU(Z)\n",
    "            memory[f'Z{i}'] = Z\n",
    "            memory[f'A{i}'] = A\n",
    "        Z = self.weights[f'W{len(self.layers) - 1}'] @ A + self.weights[f'b{len(self.layers) - 1}']\n",
    "        A = self.softmax(Z)\n",
    "        memory[f'Z{len(self.layers) - 1}'] = Z\n",
    "        memory[f'A{len(self.layers) - 1}'] = A\n",
    "        return memory\n",
    "\n",
    "    # derivative of ReLU activation function\n",
    "    def ReLU_deriv(self, Z):\n",
    "        return Z > 0\n",
    "\n",
    "    def cross_entropy(self, one_hot_Y, pred_Y, epsilon=1e-12):\n",
    "        \"\"\"\n",
    "        calculate the cross-entropy loss.\n",
    "        :param one_hot_Y: One-hot encoded true labels\n",
    "        :param pred_Y: Predicted labels\n",
    "        :param epsilon: Small value to avoid division by zero\n",
    "        :return: Cross-entropy loss\n",
    "        \"\"\"\n",
    "        clip_pred_y = np.clip(pred_Y, epsilon, 1. - epsilon)  # clip predictions to avoid values of 0 and 1\n",
    "        loss = -np.mean(np.sum(one_hot_Y * np.log(clip_pred_y), axis=0))\n",
    "        return loss\n",
    "\n",
    "    def one_hot(self, Y):\n",
    "        \"\"\"\n",
    "        convert labels to one hot encoding\n",
    "        :param Y: True labels\n",
    "        :return: One hot labels\n",
    "        \"\"\"\n",
    "        one_hot_Y = np.zeros((self.layers[-1], Y.size))\n",
    "        one_hot_Y[Y, np.arange(Y.size)] = 1\n",
    "        return one_hot_Y\n",
    "\n",
    "    def backward_prop(self, memory, X, Y):\n",
    "        \"\"\"\n",
    "        Perform backward propagation through the network \n",
    "        :param memory: dictionary containing previous results\n",
    "        :param X: Input data\n",
    "        :param Y: True labels\n",
    "        :return: Dictionary of gradients\n",
    "        \"\"\"\n",
    "        gradients = {}\n",
    "        one_hot_Y = self.one_hot(Y)\n",
    "        m = X.shape[1]\n",
    "        A_last = memory[f'A{len(self.layers) - 1}']\n",
    "        dZ = A_last - one_hot_Y\n",
    "        gradients[f'dW{len(self.layers) - 1}'] = 1 / m * dZ @ memory[f'A{len(self.layers) - 2}'].T\n",
    "        gradients[f'db{len(self.layers) - 1}'] = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n",
    "        for i in range(len(self.layers) - 2, 0, -1):\n",
    "            dZ = (self.weights[f'W{i + 1}'].T @ dZ) * self.ReLU_deriv(memory[f'Z{i}'])\n",
    "            gradients[f'dW{i}'] = 1 / m * dZ @ memory[f'A{i - 1}'].T\n",
    "            gradients[f'db{i}'] = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n",
    "        return gradients\n",
    "\n",
    "    def update_weights(self, gradients):\n",
    "        \"\"\"\n",
    "        Update the weights and biases of the network using the computed gradients \n",
    "        :param gradients: Dictionary of gradients\n",
    "        \"\"\"\n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.weights[f'W{i}'] -= self.learning_rate * gradients[f'dW{i}']\n",
    "            self.weights[f'b{i}'] -= self.learning_rate * gradients[f'db{i}']\n",
    "            \n",
    "    def plot_training_history(self, accuracy_history, loss_history):\n",
    "        \"\"\"\n",
    "        Plot the training and validation loss over iterations \n",
    "        :param accuracy_history: List of accuracy values over iterations\n",
    "        :param loss_history: List of loss values over iterations\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(range(len(accuracy_history)), accuracy_history, label='validation Loss', color='blue')\n",
    "        plt.plot(range(len(loss_history)), loss_history, label='Training Loss', color='green', linestyle='dotted')\n",
    "        plt.title(f\"Network's Configuration: {self.layers}\")\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    # Plot the confusion matrix    \n",
    "    def plot_confusion_matrix(self, X, Y):\n",
    "        predictions = self.predict(X)\n",
    "        cm = confusion_matrix(Y, predictions)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap='viridis')\n",
    "        plt.title(f'Confusion Matrix for Model configuration: layers = {self.layers}, learning_rate = {self.learning_rate}, batch_size = {self.batch_size}, iterations = {self.iterations}', fontsize=10)\n",
    "        plt.show()\n",
    "     \n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"\n",
    "        Train the neural network on the given data - updates the weights (and biases) of neurons network\n",
    "        by using the gradient descent algorithm.\n",
    "        :param X: Input data\n",
    "        :param Y: True labels\n",
    "        \"\"\"\n",
    "        val_loss_history = []\n",
    "        train_loss_history = []\n",
    "        \n",
    "        for i in range(self.iterations):\n",
    "            X, Y = shuffle(X.T, Y)\n",
    "            X = X.T\n",
    "            batches = [(X[:, k:k + self.batch_size], Y[k:k + self.batch_size]) for k in\n",
    "                       range(0, X.shape[1], self.batch_size)]\n",
    "            for batch_X, batch_Y in batches:\n",
    "                memory = self.forward_prop(batch_X)\n",
    "                gradients = self.backward_prop(memory, batch_X, batch_Y)\n",
    "                self.update_weights(gradients)\n",
    "            \n",
    "              # calculate training loss\n",
    "            memory = self.forward_prop(X)\n",
    "            one_hot_Y = self.one_hot(Y)\n",
    "            train_loss = self.cross_entropy(one_hot_Y, memory[f'A{len(self.layers) - 1}'])\n",
    "            train_loss_history.append(train_loss)\n",
    "            \n",
    "            # calculate validation loss\n",
    "            memory_val = self.forward_prop(X_val)\n",
    "            one_hot_val_Y = self.one_hot(y_val)\n",
    "            val_loss = self.cross_entropy(one_hot_val_Y, memory_val[f'A{len(self.layers) - 1}'])\n",
    "            val_loss_history.append(val_loss)\n",
    "            \n",
    "            if i % 5 == 0 or i == self.iterations - 1:\n",
    "                print(\"-----------------------------------\\n\")\n",
    "                print(f\"Iteration {i}, Training Accuracy: {self.score(X, Y)}, Training Loss: {train_loss}\")\n",
    "        self.plot_training_history(train_loss_history, val_loss_history)             \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        predict labels for the given input data\n",
    "        :param X: Input data\n",
    "        :return: Predicted labels\n",
    "        \"\"\"\n",
    "        memory = self.forward_prop(X)\n",
    "        A_last = memory[f'A{len(self.layers) - 1}']\n",
    "        return np.argmax(A_last, axis=0)\n",
    "\n",
    "    def score(self, X, Y):\n",
    "        \"\"\"\n",
    "        Calculate the accuracy of the model on the given data\n",
    "        :param X: Input data\n",
    "        :param Y: True labels\n",
    "        :return: Accuracy of the model\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == Y)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d448abe1c2f837f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Load datasets\n",
    "train_data = pd.read_csv('MNIST-train.csv')\n",
    "test_data = pd.read_csv('MNIST-test.csv')\n",
    "\n",
    "# Shuffle and split the training data\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "test_data = test_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X_train_full = train_data.iloc[:, :-1].values  # Features (all columns except the last one)\n",
    "y_train_full = train_data.iloc[:, -1].values  # Labels (last column)\n",
    "\n",
    "# Split into training (90%) and validation (10%) sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1, random_state=42)\n",
    "\n",
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = test_data.iloc[:, :-1].values / 255.0\n",
    "y_test = test_data.iloc[:, -1].values\n",
    "\n",
    "# Transpose to match the format\n",
    "X_train = X_train.T\n",
    "X_val = X_val.T\n",
    "X_test = X_test.T"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d47b4241b91b43a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the different sets of configurations to test, each one with a different isolated parameter\n",
    "layer_configs = [\n",
    "     {'layers': [784, 128, 64, 10]},\n",
    "    {'layers': [784, 10, 10]},\n",
    "    {'layers': [784, 128, 64, 32, 10]},\n",
    "    {'layers': [784, 10]},\n",
    "     {'layers': [784, 256, 128, 32, 10]},\n",
    "]\n",
    "\n",
    "\n",
    "learning_rate_configs = [\n",
    "    {'learning_rate': 0.1},\n",
    "    {'learning_rate': 0.01},\n",
    "    {'learning_rate': 0.001},\n",
    "    {'learning_rate': 0.005},\n",
    "]\n",
    "\n",
    "batch_size_configs = [\n",
    "    {'batch_size': 8},\n",
    "    {'batch_size': 32},\n",
    "    {'batch_size': 64},\n",
    "    {'batch_size': 1}\n",
    "]\n",
    "\n",
    "iteration_configs = [\n",
    "    {'iterations': 1},\n",
    "    {'iterations': 10},\n",
    "    {'iterations': 30},\n",
    "    {'iterations': 100},\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e80aa373101468e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test and plot for each isolated parameter\n",
    "for config_set, param_name in [(layer_configs, 'layers'), (learning_rate_configs, 'learning_rate'), (batch_size_configs, 'batch_size'), (iteration_configs, 'iterations')]:\n",
    "    results = test_configuration_set(X_train, y_train, X_val, y_val, X_test, y_test, config_set, param_name)\n",
    "    plot_test_scores(results, param_name)\n",
    "\n",
    "# Print the top 3 models\n",
    "print(\"\\nTop 3 Models:\")\n",
    "top3_models = sorted(top3_models, key=lambda x: x['test_score'], reverse=True)\n",
    "for model in top3_models:\n",
    "    model['train_score'] = float(model['train_score'])\n",
    "    model['val_score'] = float(model['val_score'])\n",
    "    model['test_score'] = float(model['test_score'])\n",
    "    print(f\"Validation Score: {model['test_score']}\")\n",
    "    print(f\"Model Configuration: {model}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5995e5d15df58d06"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
